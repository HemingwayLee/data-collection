# data-collection teams
* plan, collect, manage, valid, report (visualization)
  * Fake data generation is important
* data structure, konwledge about business
* data analytics, statistical analysis
* survey design
* SQL, tablau, excel, and google doc
* continuously eavluate existing tools and process
  * How to evaluate their labelling
    * Check it randomly
    * Tool to evaluate
* work with temporary employee (training and task management)

## Data pipeline related services
* data migration or ETL 
* data cleaning (e.g., OpenRefine)
* data labelling
  * It should be highly customized
  * It contains domain knowledge
  * It needs AI engineers/data scientists to clearify some of the labelling
* data versioning and diff (e.g., Data Version Control (DEV))
  * hard to do because the size is too big
* data visualization (e.g., Kaggle csv viewer)
  * It should be customized
* It requires security, infrastructure, and data storage knowledge

# Software Engineering  
https://arxiv.org/pdf/1810.12034.pdf  
https://www.microsoft.com/en-us/research/uploads/prod/2019/03/amershi-icse-2019_Software_Engineering_for_Machine_Learning.pdf  

# MLOps

# Public datasets  

https://github.com/awesomedata/awesome-public-datasets  

# Data Cleaning Tool  
http://openrefine.org/  

# Ref  
https://www.analyticsvidhya.com/blog/2018/11/data-engineer-comprehensive-list-resources-get-started/  
https://towardsdatascience.com/data-science-for-startups-data-pipelines-786f6746a59a  
