# data-collection teams
* plan, collect, manage, valid, report (visualization)
  * Fake data generation is important
    * PS works
* data structure and konwledge about business
* data analytics and statistical analysis
* survey design
* SQL, tablau, excel, and google doc
* continuously eavluate existing tools and process
  * How to evaluate their labelling
    * Check it randomly
    * Tool to evaluate
    * Find a leader among them
    * Weekly meeting
* work with temporary employee (training and task management)
  * Knows the contracts (e.g., NDA), agency, and law
  * Need to provide clear job/project description and deadline
  * Interns are leaglly to learn
    * They need a mentor

## Data pipeline related services
* data migration or ETL 
* data cleaning
  * [SmartOCR](https://www.smartocr.jp/)
  * [OpenRefine](https://openrefine.org/)
* data labelling
  * It should be highly customized
  * It contains domain knowledge
  * It needs AI engineers/data scientists to clearify some of the labelling
* data versioning and diff (e.g., Data Version Control (DEV))
  * hard to do because the size is too big
* data visualization (e.g., Kaggle csv viewer)
  * It should be customized
* It requires security, infrastructure, and data storage knowledge

# What to show on report
* Basic info
  * size, datetime
* How it perform
  * test on unseen data
  * accuracy (or F1, recall, ...), confusion matrix
    * details on subset of data
  * running performance
* What it is built
  * make it reproducable
  * add validation dataset
  * numbers over epoch

# Software Engineering  
https://arxiv.org/pdf/1810.12034.pdf  
https://www.microsoft.com/en-us/research/uploads/prod/2019/03/amershi-icse-2019_Software_Engineering_for_Machine_Learning.pdf  

# MLOps

# Public datasets  
https://github.com/awesomedata/awesome-public-datasets  

# Ref  
https://www.analyticsvidhya.com/blog/2018/11/data-engineer-comprehensive-list-resources-get-started/  
https://towardsdatascience.com/data-science-for-startups-data-pipelines-786f6746a59a  
